# First Day at The Hub — Journey Simulations

*20 personas, brutally honest first-visit narratives*
*Generated 2026-02-22*

---

## Executive Tier

### 1. Angus — Co-CEO (Digital & AI Sponsor)
**Device:** Desktop (MacBook) | **Time:** 15 mins | **Tech Comfort:** 5/5

**Entry point:** He built this. Opens localhost:8500 directly from his terminal.

**Step 1:** Lands on the login gate. Types the site password. Smooth — he set it up.
> Internal thought: "Right, login works. Good."

**Step 2:** Home page loads. Sees the 5-pillar card layout, the initiative pulse from Monday.com, and the Quick Launch grid. Clicks through to the Way of Working section.
> Internal thought: "100 initiatives tracked live. That's going to land well in the board paper."

**Step 3:** Opens Way of Working > Overview. Sees the status donut — 23 done, 31 in progress, 12 stuck, 34 not started. Clicks into Pillar View and selects P5 Digital & AI.
> Internal thought: "22 initiatives under P5, 6 done. Need to push harder on the stuck ones."

**Step 4:** Navigates to AI Adoption page. Sees the tracker but it's mostly structural — no live user telemetry showing who's actually using which pages.
> Internal thought: "I can see what exists but not who's using it. I need adoption metrics — logins by department, page views, feature usage. That's a gap."

**Step 5:** Opens Prompt Engine. Selects "Store Performance Analysis" task type, generates a prompt using Claude. The output is solid, references real store data.
> Internal thought: "The prompt quality is good. But I can't see aggregate Rubric scores across all users. I need a dashboard showing average scores, top users, adoption by department."

**Step 6:** Checks The Rubric page — can score a prompt output manually. Sees the 8-criteria framework and 5-tier advanced scoring.
> Internal thought: "The scoring framework is solid. But there's no rollup view — I can't see 'Marketing team averages 7.2, Ops team averages 8.1'. That's what I need for the board."

**Step 7:** Opens Mission Control. Finds the Documentation tab, Data Catalog, Showcase, Self-Improvement Engine. The Showcase shows WATCHDOG governance scores.
> Internal thought: "This is the control room I need. But it's developer-focused. I need an executive view — a single page that shows: adoption metrics, quality scores, initiative progress, and ROI indicators. One page, five numbers."

**Journey Outcome:**
- Wins: Monday.com integration works beautifully. Way of Working gives real initiative visibility. Prompt Engine generates quality output.
- Friction: No aggregate adoption metrics (who's using what, how often). No executive dashboard with the 5 numbers he needs for the board.
- Drop-off risk: Low — he's the sponsor. But he'll be frustrated presenting without adoption data.
- "Aha moment": Way of Working pulling 100 live initiatives from Monday.com across all 5 pillars.
- Time to value: 2 minutes (seeing Monday.com data on the homepage).

---

### 2. Damien — CFO
**Device:** Desktop (Windows) | **Time:** 5 mins | **Tech Comfort:** 3/5

**Entry point:** Angus sent him a link: "Check out the Sales dashboard on The Hub."

**Step 1:** Hits the login gate. Fumbles the site password. Types it wrong twice (it's case-sensitive). Third attempt works.
> Internal thought: "Why do I need a password for an internal tool? Shouldn't this use SSO?"

**Step 2:** Lands on Home. Sees colourful cards with pillar names. None of them say "Finance" or "P&L". Scans for something familiar.
> Internal thought: "Greater Goodness? Growing Legends? What is this? Where's the financial data?"

**Step 3:** Spots "Operations" in the nav bar. Clicks it. Sees the intro page with strategic framing about "running tighter, smarter, faster."
> Internal thought: "Skip the marketing speak. Where are the numbers?"

**Step 4:** Clicks through to Sales dashboard. Sees weekly revenue by store, department splits, YoY comparison. The numbers look plausible.
> Internal thought: "OK, $47M last week across all stores. That's in the right ballpark. But these are POS numbers, not the reconciled figures from FloQast. I can't use these for reporting."

**Step 5:** Clicks Profitability. Sees gross profit by department, margin trends. Useful directionally.
> Internal thought: "The margin trends are interesting — produce at 38%, deli at 42%. But I need net margin after labour and waste, not just gross. And I can't export this to Excel easily."

**Step 6:** Looks for an export button. Finds nothing obvious on the Sales page. Time's up.
> Internal thought: "I can see directional data but I can't action any of it. No export, no reconciliation with our finance system. I'll tell Rebecca to check if the numbers match but I'm not switching from FloQast."

**Journey Outcome:**
- Wins: Sales and profitability data is real and directionally correct. Store-by-store view is useful.
- Friction: No "Finance" section in nav. No Excel export on Sales. No connection to FloQast or ERP. Pillar names are confusing — he doesn't think in "Greater Goodness" terms.
- Drop-off risk: HIGH. He got some value but nothing he can't get from existing tools. Won't return unless someone shows him something new.
- "Aha moment": None. Confirmed existing data exists in a new format but didn't discover anything new.
- Time to value: 3 minutes (seeing sales data), but not actionable value.

---

### 3. Sean — Head of Operations
**Device:** Desktop | **Time:** 15 mins | **Tech Comfort:** 3/5

**Entry point:** Weekly ops meeting — someone mentioned "The Hub has store ops data now."

**Step 1:** Logs in successfully. Lands on Home. Immediately clicks "Operations" in the top nav.
> Internal thought: "OK, Operations HQ. Let's see what's here."

**Step 2:** Sees the Operations intro page with live revenue and GP% metrics pulled from the database. 43 stores, 383M transaction rows. That's impressive.
> Internal thought: "They've got our data in here. Let's see if I can drill into individual stores."

**Step 3:** Clicks through to Sales. Selects his problem store (Orange) from the filter. Sees weekly trend, department breakdown, YoY comparison.
> Internal thought: "Orange is down 4% YoY in produce. That matches what the store manager told me. But now I can see it in data."

**Step 4:** Moves to Store Ops. Finds store-level operational metrics, labour data gaps.
> Internal thought: "Store ops is a good start but it's missing labour hours and waste data. Those are the two things I need to understand profitability properly."

**Step 5:** Clicks Buying Hub. Sees supplier/buyer analysis, category trends.
> Internal thought: "This is interesting — I can see buying patterns across the network. If James in procurement is using this, we could identify over-buying patterns."

**Step 6:** Opens PLU Intelligence. Searches for "avocado". Finds PLU-level data across 43 stores — volume, revenue, margin, trend.
> Internal thought: "This is genuinely useful. I've never been able to see PLU-level performance across all stores in one place. It's always been store-by-store reports."

**Step 7:** Opens Transport. Sees transport cost data and delivery tracking.
> Internal thought: "Basic but useful. If they added route optimisation and real-time tracking this would be excellent."

**Journey Outcome:**
- Wins: PLU Intelligence is a genuine breakthrough — network-wide SKU visibility. Sales by store works well. Revenue data is real.
- Friction: Missing labour hours and waste data in Store Ops. Transport is basic. No connection to existing operational tools (WMS, TMS).
- Drop-off risk: LOW. PLU Intelligence alone is enough to bring him back.
- "Aha moment": PLU Intelligence — seeing avocado performance across 43 stores in one query.
- Time to value: 4 minutes (seeing store-specific sales data).

---

### 4. Laura — Head of People & Culture
**Device:** Desktop | **Time:** 15 mins | **Tech Comfort:** 3/5

**Entry point:** Phil mentioned The Hub has a learning platform. She wants to check it out for the team.

**Step 1:** Logs in. Lands on Home. Spots "People" section — "Growing Legendary Leadership". Clicks.
> Internal thought: "Growing Legendary Leadership — that's our pillar language. Good."

**Step 2:** Sees the People intro page. Live metrics: Academy users and XP from the gamification engine, Prompt Engine submission count. eNPS and turnover rate show "Coming Soon" cards.
> Internal thought: "Coming Soon on eNPS? That's literally my most important metric. I need that in here yesterday."

**Step 3:** Clicks Learning Centre. Finds the knowledge base — 543 articles covering Company Policy, Store Operations, Perish-ables, People & Culture. Can search and browse by category.
> Internal thought: "543 articles. That's our whole NUTS library digitised. This is actually really useful for onboarding."

**Step 4:** Opens Academy. Sees XP levels (Seed to Legend), daily challenges, streaks, badges, leaderboard. It's gamified learning.
> Internal thought: "Gamification. The store teams will either love this or think it's patronising. Need to test with a few stores first. But the framework is solid."

**Step 5:** Checks the Leaderboard tab. Empty — no users have earned XP yet.
> Internal thought: "Empty leaderboard. That's fine, it's new. But when I present this to the board, they'll ask about engagement numbers. I need to plan a pilot."

**Step 6:** Opens Prompt Engine. Selects her role context. Finds templates filtered for People & Culture — "Team Development Plan", "Onboarding Checklist". Generates one.
> Internal thought: "OK, the AI-generated development plan is reasonable. Not perfect but a decent starting point. The Rubric scoring is clever — forces quality."

**Step 7:** Checks The Paddock (innovation sandbox) and Hub Assistant (AI chatbot). The Paddock is sparse. Hub Assistant works — can ask questions about company policies and it searches the knowledge base.
> Internal thought: "Hub Assistant is useful for new starters. 'What's our leave policy?' and it finds the answer from the NUTS library. That saves HR admin time."

**Journey Outcome:**
- Wins: Learning Centre (543 NUTS articles), Hub Assistant for policy Q&A, Academy gamification framework is solid. People intro page shows real data.
- Friction: eNPS "Coming Soon" is her most critical metric. Empty leaderboard means no proof of engagement yet. No connection to Dayforce (their HCM system).
- Drop-off risk: MEDIUM. She sees potential but needs eNPS and Dayforce integration to make it central to her workflow.
- "Aha moment": Hub Assistant answering policy questions from the NUTS library — potential to reduce HR admin load.
- Time to value: 5 minutes (finding the NUTS articles in Learning Centre).

---

### 5. Phil — CTO / Head of Transformation (Hub Owner)
**Device:** Desktop | **Time:** 30 mins | **Tech Comfort:** 5/5

**Entry point:** He's running the Platform. Opens it to prepare his board paper section.

**Step 1:** Logs in. Home page. Immediately checks the Monday.com initiative pulse — all 5 pillars showing live data.
> Internal thought: "Good, the Monday.com integration is working. P1 has 15 initiatives, P4 has 24. I can reference these directly in the board paper."

**Step 2:** Opens Way of Working. Checks the Overview — donut chart shows 23% done, 31% in progress, 12% stuck. Drills into "Stuck" items.
> Internal thought: "12 stuck initiatives. I need to flag these in the weekly standup. The pillar view lets me see exactly which ones and who owns them."

**Step 3:** Navigates to Mission Control > Showcase tab. Sees WATCHDOG governance scores, 657+ tests, score radar chart.
> Internal thought: "Governance scores are healthy — all criteria above 7. I can use the radar chart in the board slide."

**Step 4:** Opens Mission Control > Data Catalog. Sees all data sources documented: transactions (383M rows), weekly sales (1.6M), customers (17K), market share (77K).
> Internal thought: "The data catalog is comprehensive. But for the board, I need to show adoption — who's actually using this data. Page views, active users, sessions by department."

**Step 5:** Checks Academy metrics. Sees the framework but no active users yet.
> Internal thought: "Need to get the pilot running before the board presentation. Even 10 users with real XP would demonstrate the concept."

**Step 6:** Opens AI Adoption page. Finds adoption tracking framework.
> Internal thought: "The framework is here but the data is self-referential — it tracks Hub features, not actual adoption by humans. I need: unique users per week, pages per session, feature usage by role."

**Step 7:** Checks the Prompt Engine quality — looks at PtA leaderboard, submission counts.
> Internal thought: "Zero submissions in PtA yet. Same problem — framework is solid but no real-world usage data to present."

**Step 8:** Steps back and thinks about what he'd tell the board.
> Internal thought: "The platform is impressive technically — 33 pages, 147 API endpoints, 383M rows of data, Monday.com integration, gamification engine. But I can't prove anyone outside the build team has used it. I need: (1) a pilot group of 10-20 users, (2) usage analytics, (3) at least one 'wow' metric — like 'PLU Intelligence saved 4 hours of manual reporting per week'."

**Journey Outcome:**
- Wins: Platform is technically comprehensive. Monday.com integration gives board-ready initiative data. Data catalog and governance are solid.
- Friction: No usage analytics (active users, page views, feature adoption). No real-world usage to demonstrate — everything is framework, nothing is proven with users.
- Drop-off risk: Zero — he owns it. But he's stressed about the board presentation gap.
- "Aha moment": Realising the platform needs a pilot before the board presentation, not more features.
- Time to value: Immediate (he knows the platform). But time to board-presentable value: needs 2-3 weeks of pilot data.

---

## Store Tier

### 6. Karen — Store Manager, Bondi Junction (Large Format)
**Device:** iPad (store office) | **Time:** 5 mins | **Tech Comfort:** 3/5

**Entry point:** Regional Manager email: "All store managers, please log into The Hub and check your store's sales data."

**Step 1:** Opens the link on her iPad. Login gate appears. Types the site password from the email.
> Internal thought: "Another platform. OK, let's see if this is actually useful."

**Step 2:** Home page loads. On iPad it's a bit cramped — 8 columns in the top nav are squished. She can read the pillar names but they're small.
> Internal thought: "What do I click? I want my store's sales. Is it 'Operations' or 'Customer'?"

**Step 3:** Taps Operations. Sees the intro page with strategic framing. Scrolls past it quickly.
> Internal thought: "I don't need the strategy pitch. Where's my store data?"

**Step 4:** Finds Sales in the sub-nav. The page loads with weekly revenue. She looks for a store filter — finds it. Selects "Bondi Westfield" (Store 65).
> Internal thought: "There it is. $1.2M last week. Down 2% on last year. Produce is flat, deli up 6%. OK, that's useful."

**Step 5:** Scrolls down to see department breakdown and YoY comparison chart.
> Internal thought: "I can see exactly which departments are pulling their weight. If I could show this to my department managers in the Monday meeting, that'd be powerful."

**Step 6:** Time's up. Closes the browser.
> Internal thought: "Sales data is useful. I'll check it before the Monday meeting each week. But I wish I could pin my store as default so I don't have to filter every time."

**Journey Outcome:**
- Wins: Store-level sales data with department breakdown. Real numbers that match her reality.
- Friction: No "pin my store" default. iPad layout is cramped on the top nav. Strategic intro page is a speed bump for someone with 5 minutes.
- Drop-off risk: LOW — the sales data is genuinely useful for her Monday meeting prep.
- "Aha moment": Seeing department-level YoY comparison for her store in one view.
- Time to value: 3 minutes (finding and filtering to her store).

---

### 7. Trevor — Store Manager, Leura (Small Format)
**Device:** Shared back-office PC | **Time:** 5 mins | **Tech Comfort:** 2/5

**Entry point:** District Manager mentioned it at a meeting. Trevor types "harris farm hub" into Google.

**Step 1:** Google doesn't find it — it's an internal tool. He asks his 2IC for the link. Gets it 10 minutes later.
> Internal thought: "Why isn't this on the intranet? Nobody told me the address."

**Step 2:** Opens the link on the shared PC. Login gate. He doesn't have the password. Sends a text to his DM asking for it. Waits 5 more minutes.
> Internal thought: "Already 15 minutes and I haven't seen anything. This is exactly what I expected."

**Step 3:** Finally logs in. Home page loads. Lots of information. He doesn't know where to start. Scrolls aimlessly.
> Internal thought: "Five pillars? I just want to know how my store's going. Where do I even click?"

**Step 4:** Spots "Operations" in the nav. Clicks it. Sees the strategic intro. Reads the first line, gets impatient.
> Internal thought: "Are we running tighter, smarter and faster? Mate, I'm trying to find my sales report."

**Step 5:** Finds Sales eventually. Looks for his store — "Leura". Types it in the filter. His store doesn't appear in the first dropdown — it might be listed by number, not name. Gets confused.
> Internal thought: "I can't find my store. Is it listed as '51' or 'Bowral'? Wait, Leura and Bowral are different things..."

**Step 6:** Gives up. Closes the browser. Goes back to checking yesterday's POS report the old way.
> Internal thought: "15 minutes wasted. I'll stick to what works."

**Journey Outcome:**
- Wins: None for this user.
- Friction: Discovery (how to find the URL), password access, navigation confusion, store filter confusion (number vs name).
- Drop-off risk: CRITICAL. He's gone and won't come back without a guided walkthrough.
- "Aha moment": None. He never got to the data.
- Time to value: Never reached value.

---

### 8. Marco — Department Manager, Produce (Drummoyne)
**Device:** Phone (iPhone, one hand free) | **Time:** 2 mins | **Tech Comfort:** 2/5

**Entry point:** Zara (his weekend buyer) showed him on her phone: "You can look up PLU codes on this."

**Step 1:** Opens the link on his phone. Login gate fills the screen. Types the password with one thumb while holding a crate of nectarines.
> Internal thought: "Hurry up."

**Step 2:** Home page loads on mobile. The top nav row is completely illegible on a phone — 8 tiny columns with icons he can't read. The sidebar is collapsed.
> Internal thought: "Can't read anything. Where's the PLU thing Zara showed me?"

**Step 3:** Tries to find PLU Intelligence. Taps around. The sidebar has a navigation list but the text is small. He scrolls through 33 pages.
> Internal thought: "Too many options. I just want PLU lookup."

**Step 4:** Finds PLU Intelligence after 90 seconds of scrolling. Taps it. The page loads with filters — Store, Department, Date Range. Too many fields for a quick lookup.
> Internal thought: "I don't want to analyse anything. I just want to know the PLU code for finger limes. This isn't a lookup, it's a dashboard."

**Step 5:** His 2 minutes are up. A delivery truck is waiting.
> Internal thought: "I'll ask Zara to look it up. This isn't for me."

**Journey Outcome:**
- Wins: None for this user at this time.
- Friction: Mobile layout is unusable for the top nav. Too many pages to scroll through. PLU Intelligence is an analytics dashboard, not a quick lookup tool.
- Drop-off risk: CRITICAL. 2-minute users need a completely different UX — a search bar that says "Type a PLU code or product name" and returns one answer.
- "Aha moment": None.
- Time to value: Never reached value. Needed a 10-second lookup, got a 10-minute analytics tool.

---

### 9. Zara — Weekend Buyer (Part-Time, Marrickville)
**Device:** Phone (Android) | **Time:** 5 mins | **Tech Comfort:** 4/5

**Entry point:** Heard about the Prompt Engine from a colleague at uni who works at another company using AI tools.

**Step 1:** Logs in on her phone. Home page loads. She's digitally native — immediately spots the sidebar nav and expands it.
> Internal thought: "OK, lots of pages. Where's the AI stuff?"

**Step 2:** Finds Prompt Engine in the sidebar under "Growing Legendary Leadership". Taps it.
> Internal thought: "Prompt Engine. Sounds cool."

**Step 3:** The page loads with a role selector and task type dropdown. She picks "Weekend Buyer" role (if available) or "General". Sees task templates: "Store Performance Analysis", "Product Trend Report".
> Internal thought: "I want to write something about buying decisions for this weekend. Let me try 'Product Trend Report'."

**Step 4:** The default prompt template loads. She edits it to ask about stone fruit trends for Marrickville. Hits Generate. The AI returns a structured analysis with seasonal data.
> Internal thought: "Wait, this actually knows about our products? It's pulling real data? That's way better than ChatGPT for this."

**Step 5:** Tries the Rubric scoring on her output. Gets a 7.8 — "REVISE". The feedback says she needs more specific time ranges and to cite data sources.
> Internal thought: "7.8 is not bad for my first try. The feedback is actually useful — I should specify 'last 4 weeks' not just 'recently'."

**Step 6:** Checks the Academy briefly. Sees she could earn XP for using the Prompt Engine.
> Internal thought: "XP and badges? Like a game? I'm into this. I'll try to get a higher score next time."

**Journey Outcome:**
- Wins: Prompt Engine works well for her use case. Rubric feedback is genuinely educational. Gamification (XP/badges) hooks her engagement style.
- Friction: Finding the Prompt Engine required knowing to look in the sidebar. Role filtering could be more intuitive.
- Drop-off risk: LOW. She's a natural advocate — will tell other young staff.
- "Aha moment": Discovering the AI knows about Harris Farm products and can generate store-specific analysis.
- Time to value: 3 minutes (generating her first prompt output).

---

### 10. Bella — Front-of-House Team Member (Casual, Week 1)
**Device:** Phone | **Time:** 5 mins | **Tech Comfort:** 4/5

**Entry point:** Store manager said "check out The Hub" during her break.

**Step 1:** Opens the link. Login gate. She doesn't have the password. Asks the manager. Gets it. Types it in.
> Internal thought: "OK, I'm in. What is this?"

**Step 2:** Home page loads. Sees "Harris Farm Hub — Centre of Excellence". Five pillar cards. She doesn't know what any of the pillars mean.
> Internal thought: "For The Greater Goodness? Digital & AI? I just started. I don't know what any of this means."

**Step 3:** Spots "Greater Goodness" and clicks it — that's the one that sounded like it explains what the company is about.
> Internal thought: "Oh, this is about sustainability and B-Corp. That's actually cool. I picked this job because they care about the environment."

**Step 4:** Goes back to Home. Tries to find onboarding content. Clicks "People" > "Learning Centre".
> Internal thought: "Learning Centre! This should have the induction stuff."

**Step 5:** Learning Centre loads. Searches "onboarding" — finds NUTS articles about Dayforce onboarding forms, company policies. Useful but dry.
> Internal thought: "OK, so there's info about filling in my forms. But I was hoping for something more like 'Welcome to Harris Farm, here's what you need to know in your first week.'"

**Step 6:** Tries Hub Assistant. Types "What should I know in my first week?" Gets a helpful response pulling from the knowledge base — company values, key policies, where to find things.
> Internal thought: "Oh, this is actually helpful. It's like having a buddy who knows everything about the company."

**Journey Outcome:**
- Wins: Hub Assistant is genuinely helpful for a new starter's questions. Greater Goodness page gives her the "why" behind the company. Learning Centre has the NUTS library.
- Friction: Home page doesn't have a "New Starter? Start Here" path. Learning Centre content is procedural, not welcoming. No guided first-week journey.
- Drop-off risk: MEDIUM. She got value from Hub Assistant but the overall experience was "figure it out yourself."
- "Aha moment": Hub Assistant answering her "first week" question coherently.
- Time to value: 4 minutes (Hub Assistant).

---

## Supply Chain Tier

### 11. Darren — Warehouse Floor Operator (Flemington DC)
**Device:** Shared terminal (standing desk) | **Time:** 2 mins | **Tech Comfort:** 1/5

**Entry point:** Supervisor said "Everyone needs to log into The Hub and complete the safety module."

**Step 1:** Walks to the shared terminal. The browser is already open to someone else's session. He doesn't know if he needs to log out first. Types the URL.
> Internal thought: "What's the address again?"

**Step 2:** The previous person's session is still active (Streamlit session state persists). He sees someone else's data. Confused.
> Internal thought: "This isn't mine. Who's Angus? Why am I seeing his XP?"

**Step 3:** Refreshes the page. Gets the login gate. Types the shared site password.
> Internal thought: "Right, I'm in. Now what?"

**Step 4:** Home page. Overwhelming. He wants the "safety module" his supervisor mentioned. Types "safety" in... there's no search bar on the home page.
> Internal thought: "Where do I search? There's no search bar."

**Step 5:** Clicks randomly. Ends up on Revenue Bridge. Numbers everywhere. Totally lost.
> Internal thought: "I don't know what this is. I need to get back to the floor."

**Step 6:** Closes the browser. Tells his supervisor he "couldn't find it."
> Internal thought: "This isn't for people like me."

**Journey Outcome:**
- Wins: None.
- Friction: No search on home page. Shared terminal session confusion. No task-based entry point ("I was told to do X"). No role-based landing page.
- Drop-off risk: CRITICAL. Without a direct link to the specific module, warehouse operators will never navigate here.
- "Aha moment": None.
- Time to value: Never reached value.

---

### 12. Priya — Transport Coordinator
**Device:** Phone (on the road) | **Time:** 5 mins | **Tech Comfort:** 3/5

**Entry point:** Saw a mention in the weekly ops email: "Transport dashboard now live on The Hub."

**Step 1:** Opens the link while parked between deliveries. Login gate. Enters password.
> Internal thought: "OK, let's see this transport dashboard."

**Step 2:** Home page on phone. Finds the sidebar, navigates to Operations > Transport.
> Internal thought: "Transport. Found it."

**Step 3:** Transport dashboard loads. Sees transport cost trends, delivery data. It's informative but historical — no real-time tracking.
> Internal thought: "Cost trends are useful for my monthly report. But I was hoping for live delivery tracking — which trucks are where, which stores are waiting."

**Step 4:** Checks the data — it covers cost per delivery, store-level transport costs, route analysis.
> Internal thought: "This is good for planning. I can see which stores cost the most to deliver to. But it's a reporting tool, not an operational tool."

**Step 5:** Time's up. Bookmarks the transport page for her monthly reporting.
> Internal thought: "I'll use this for monthly cost analysis. But for daily ops, I still need the TMS."

**Journey Outcome:**
- Wins: Transport cost analysis is useful for monthly reporting. Historical data is reliable.
- Friction: No real-time tracking. No integration with TMS (Transport Management System). Not actionable for daily operations.
- Drop-off risk: LOW-MEDIUM. She'll return monthly for cost data but it won't become a daily tool.
- "Aha moment": None specific, but validated that the cost data is useful.
- Time to value: 2 minutes (seeing transport costs).

---

### 13. James — Procurement Buyer (Grower Relations)
**Device:** Desktop | **Time:** 15 mins | **Tech Comfort:** 3/5

**Entry point:** Sean (Head of Ops) mentioned the Buying Hub and PLU Intelligence during the weekly meeting.

**Step 1:** Logs in. Home page. Clicks Operations. Navigates to Buying Hub.
> Internal thought: "Let's see what data they've got on our suppliers."

**Step 2:** Buying Hub loads. Sees category-level buying patterns, supplier performance metrics, purchase trends.
> Internal thought: "This is buyer-friendly. I can see which categories we're over-indexing on and where seasonal patterns are shifting."

**Step 3:** Switches to Product Intel. Searches for "avocado" — his biggest category.
> Internal thought: "Avocado data across all stores. Volume, revenue, margin. This is what I've been building manually in Excel every week."

**Step 4:** Opens PLU Intelligence. Drills into specific PLU codes for different avocado varieties — Hass, Shepard, organic. Sees store-by-store performance.
> Internal thought: "I can see exactly which stores are selling through Shepard avos and which are over-ordering. This is gold."

**Step 5:** Checks the Market Share section in Customer Hub. Sees postcode-level market share data.
> Internal thought: "Market share by postcode — I can cross-reference this with our grower locations to optimise delivery routes."

**Step 6:** Spends remaining time exploring the data. Exports are limited but the insights are actionable.
> Internal thought: "This platform just replaced 3 of my weekly Excel reports. I need to learn how to use the Prompt Engine to automate my weekly buying brief."

**Journey Outcome:**
- Wins: Buying Hub + PLU Intelligence + Product Intel = procurement trifecta. Replaced manual Excel reporting.
- Friction: Limited export options. No direct integration with purchasing system (P2P).
- Drop-off risk: VERY LOW. This is his new weekly tool.
- "Aha moment": PLU Intelligence showing store-by-store variety performance — the data he's been building manually.
- Time to value: 3 minutes (seeing buying patterns in Buying Hub).

---

## Marketing Tier

### 14. Sophie — CMO
**Device:** Desktop (MacBook) | **Time:** 15 mins | **Tech Comfort:** 4/5

**Entry point:** Angus mentioned The Hub in the exec meeting. She's heard it has "AI tools and data dashboards."

**Step 1:** Logs in. Home page. Scans for anything that says "Marketing". Doesn't find it in the pillar structure — Marketing sits across P2 (Customer) and P5 (Digital & AI) but neither is obviously "marketing."
> Internal thought: "There's no Marketing section. Am I supposed to use Customer? Digital & AI? Neither feels like my home."

**Step 2:** Tries Customer Hub. Finds customer insights — customer counts, segmentation, market share. The market share data is detailed (postcode-level, state-level, channel breakdown).
> Internal thought: "Market share data is interesting. But this is competitive intelligence, not campaign performance. I need ROAS, not share of market."

**Step 3:** Searches for ROAS, campaign attribution, brand health. Nothing.
> Internal thought: "No ROAS tracking. No campaign attribution. No brand health dashboard. These are the three things I need for the board."

**Step 4:** Finds Marketing Assets in the nav. Clicks it. Sees the brand guidelines, campaign creatives, category filters.
> Internal thought: "OK, this is useful — brand assets in one place. The brand guidelines PDF is here. But this is an asset library, not a marketing intelligence tool."

**Step 5:** Tries the Prompt Engine. Generates a "Campaign Performance Report" prompt. The AI generates a structured template — but it's pulling from operational data (sales, products), not marketing data (impressions, clicks, conversions, ROAS).
> Internal thought: "The Prompt Engine is clever but it doesn't have access to our marketing data. It can write about sales trends but not about campaign performance because that data lives in Meta Ads Manager, Google Ads, and Klaviyo — not here."

**Step 6:** Checks the board presentation rubric criteria in her notes: Brand Health & Awareness (target 1-3), Campaign ROI & Attribution (target 1-3), Digital & CRM Performance (target 1-2), B-Corp & Values Brand Integration (target 1-2).
> Internal thought: "The Hub can't help me with ANY of these board rubric criteria right now. I'd need: (1) Meta/Google Ads API integration for ROAS, (2) Klaviyo integration for email/CRM metrics, (3) Brand tracking survey data, (4) B-Corp messaging templates. None of that exists."

**Journey Outcome:**
- Wins: Marketing Assets library is useful for asset management. Market share data provides competitive context. Prompt Engine can generate operational briefs.
- Friction: No marketing-specific data (ROAS, CPA, email rates, brand health). No ad platform integrations. No CRM/loyalty dashboard. No campaign attribution.
- Drop-off risk: HIGH. Without marketing data, The Hub is a nice asset library but not a marketing tool.
- "Aha moment": None. The gap between what exists and what she needs is too wide.
- Time to value: 2 minutes (finding Marketing Assets), but not strategic value.

---

### 15. Megan — Marketing Manager, Brand & Creative
**Device:** Desktop (Mac, dual monitor) | **Time:** 15 mins | **Tech Comfort:** 4/5

**Entry point:** Sophie told her: "Check out The Hub — there are brand assets and AI content tools."

**Step 1:** Logs in. Finds Marketing Assets in the nav. Opens it.
> Internal thought: "OK, Marketing Assets. Let's see what's here."

**Step 2:** Sees the category filters — Brand, Amazon Ads, eCommerce, Weekend Specials, OOH, Butcher Campaign. Downloads the Brand Guidelines PDF (33 MB).
> Internal thought: "Finally, the brand guidelines in a central location. I've been sending this PDF around on email for two years."

**Step 3:** Browses campaign creatives. Sees the Amazon ads, Weekend Specials social assets, OOH signage. Image previews work.
> Internal thought: "Good — all our recent campaign assets in one place. But there's no version control, no approval status, no 'current vs archived' flag. I need to know which assets are approved for use right now."

**Step 4:** Opens Prompt Engine. Selects a task template. Tries to generate social media copy for the Weekend Specials campaign.
> Internal thought: "Let me test if the AI knows our brand voice."

**Step 5:** The AI generates copy. It's serviceable but generic — "Check out our amazing weekend specials!" Not the warm, community-driven tone Harris Farm uses.
> Internal thought: "It doesn't sound like us. There's no brand voice training in this AI. It's writing like a generic retail brand, not like Harris Farm. I'd need to rewrite 80% of this."

**Step 6:** Checks if there's a way to configure the brand voice. There isn't — the Prompt Engine uses general AI models without brand-specific fine-tuning.
> Internal thought: "The concept is right but the execution needs brand voice guardrails. If I could upload our tone-of-voice document and have the AI reference it, this would be 10x more useful."

**Journey Outcome:**
- Wins: Marketing Assets centralises brand assets for the first time. Brand guidelines accessible. Campaign creative browsable.
- Friction: No version control or approval status on assets. AI-generated copy doesn't match brand voice. No brand voice configuration.
- Drop-off risk: MEDIUM. She'll use Assets for downloads but won't trust the AI for content creation without brand voice training.
- "Aha moment": Having all brand assets in one searchable, downloadable location.
- Time to value: 2 minutes (downloading brand guidelines).

---

### 16. Josh — Marketing Coordinator, Digital & CRM
**Device:** Desktop | **Time:** 15 mins | **Tech Comfort:** 4/5

**Entry point:** Megan told him to check it out for email campaign templates.

**Step 1:** Logs in. Goes to Prompt Engine. Looks for email campaign templates.
> Internal thought: "Email campaign copy — let's see if this saves me time."

**Step 2:** Finds the task templates. Selects one close to email copy. Enters context about this week's free delivery promotion for Canberra.
> Internal thought: "Let me see if the AI can write a better subject line than I usually do."

**Step 3:** The AI generates a full email — subject line, preview text, body copy, CTA. It's structured well but lacks personalisation tokens and the specific Harris Farm voice.
> Internal thought: "The structure is good. Subject line is decent. But I'd need to add merge tags, adjust the tone, and add the legal footer. It's a 60% starting point, not a finished product."

**Step 4:** Tries to find CRM data — email open rates, loyalty member stats, customer LTV.
> Internal thought: "No CRM dashboard. No Klaviyo integration. No loyalty data. I can't see if our emails are actually working."

**Step 5:** Checks Marketing Assets for campaign imagery. Downloads the Canberra free delivery creative.
> Internal thought: "At least the creative is here. But I had to go to a separate section to get it — it'd be better if Prompt Engine and Marketing Assets were connected."

**Step 6:** Opens the Customer Hub. Finds customer count data and market share but not the email/CRM metrics he needs.
> Internal thought: "Customer data exists but it's market share and transaction data, not email engagement or loyalty program data. Different universe."

**Journey Outcome:**
- Wins: Prompt Engine generates decent first-draft email copy. Marketing Assets has the campaign imagery.
- Friction: No CRM integration (Klaviyo). No email performance data. Prompt Engine and Marketing Assets are disconnected. AI copy needs manual brand voice adjustment.
- Drop-off risk: MEDIUM. He'll use Prompt Engine as a first-draft tool but it won't replace his existing workflow.
- "Aha moment": The AI generating a structured email campaign draft in 10 seconds vs his usual 30 minutes.
- Time to value: 3 minutes (first email draft generated).

---

### 17. Liam — Marketing Analyst
**Device:** Desktop (dual monitor) | **Time:** 30 mins | **Tech Comfort:** 5/5

**Entry point:** Self-directed — heard about The Hub's data capabilities and wants to see if it connects to what he already uses.

**Step 1:** Logs in. Goes straight to Customer Hub. Opens Market Share.
> Internal thought: "Market share data. This is CBAS modelled data — I know this dataset."

**Step 2:** Explores the Market Share tabs — Overview, Store Performance, Catchment Tiers, Growth Frontiers, Map. State-level, postcode-level, distance-segmented.
> Internal thought: "This is excellent. The postcode-level share data with distance tiers is exactly what I've been requesting for 6 months. And it's already segmented by channel (instore/online)."

**Step 3:** Opens the Analytics Engine. Sees: Basket Analysis, Stockout Detection, Price Dispersion, Demand Pattern, Slow Movers. Runs a basket analysis for Drummoyne.
> Internal thought: "Cross-sell analysis on 383M transactions. This would take me 3 hours in Power BI. It ran in 15 seconds."

**Step 4:** Checks if he can export results. The basket analysis shows results in a dataframe but there's no direct CSV export button.
> Internal thought: "I need to get this into Power BI. Can I export? No export button. I'll need to screenshot or ask if there's an API."

**Step 5:** Opens PLU Intelligence. Runs avocado analysis across all stores. The depth of SKU-level data is impressive.
> Internal thought: "This is the single-source-of-truth for product performance I've been arguing for. If I could connect Power BI to this backend, I'd retire 4 of my current dashboards."

**Step 6:** Looks for ROAS, campaign attribution, LTV cohort analysis. Nothing.
> Internal thought: "No marketing performance data. The Hub has operational and competitive data but zero marketing data. ROAS lives in Meta/Google, LTV lives in Klaviyo, attribution is manual. None of those are connected here."

**Step 7:** Checks the Data Catalog in Mission Control. Sees all data sources documented with schemas, join keys, grain. Well-structured.
> Internal thought: "The data architecture is solid. If they exposed a read-only SQL endpoint or API, I could connect Power BI directly and build my own views."

**Journey Outcome:**
- Wins: Market share data (CBAS, postcode-level, distance-tiered) is a breakthrough. Analytics Engine runs cross-sell analysis on 383M rows in seconds. PLU Intelligence is comprehensive. Data catalog is well-documented.
- Friction: No export/CSV on analytics results. No marketing performance data (ROAS, CPA, LTV). No Power BI connector. No campaign attribution.
- Drop-off risk: LOW. The operational and competitive data alone is worth his time. He'll work around the export limitation.
- "Aha moment": Running basket analysis on 383M transactions in 15 seconds.
- Time to value: 2 minutes (seeing postcode-level market share data).

---

### 18. Tilly — Content Creator / Social Media Specialist
**Device:** Phone + Desktop | **Time:** 15 mins | **Tech Comfort:** 5/5

**Entry point:** Josh mentioned it. She opened it on her phone first while editing a reel.

**Step 1:** Opens on phone. Login gate. Password entry. Home page loads.
> Internal thought: "Let me find the AI content tools."

**Step 2:** Finds Prompt Engine in the sidebar. Opens it. Selects a task type. The page is functional on mobile but the text area for entering prompts is awkward to type in on a phone.
> Internal thought: "I'll switch to desktop for this."

**Step 3:** Opens on desktop. Goes to Prompt Engine. Enters: "Write 5 Instagram captions for Harris Farm Weekend Specials — stone fruit, seafood, flowers. Tone: warm, community, family. Include emojis and hashtags."
> Internal thought: "Let's see if it can do social."

**Step 4:** The AI generates 5 captions. They're... fine. Generic-warm. Correct products mentioned. But they read like AI — too polished, missing the authentic Harris Farm voice.
> Internal thought: "These are ChatGPT-level. I can get this from ChatGPT directly without logging into a separate platform. What does The Hub add that ChatGPT doesn't?"

**Step 5:** Checks the Rubric scoring on her captions. Gets a 7.2 — "REVISE". Feedback says to add specific store context and data references.
> Internal thought: "The Rubric expects data-backed content, not social captions. The scoring framework is designed for analytical prompts, not creative content. A good Instagram caption doesn't need a data citation."

**Step 6:** Browses Marketing Assets. Downloads some campaign photos for her Stories.
> Internal thought: "Asset library is handy. But no image cropping, no template overlay, no brand-approved caption library. I still need Canva for everything visual."

**Step 7:** Checks Trending. Sees product trend data — which products are selling well across stores this week.
> Internal thought: "Oh wait — this is actually useful. If I know that organic strawberries are trending up 30% this week, I can create content around that. Data-driven content creation."

**Step 8:** Opens the Customer Hub to see which postcodes have the highest market share — potential for location-specific content.
> Internal thought: "I could create location-specific social content. 'Mosman, you bought 3 tonnes of Barossa Valley cherries this month. You have excellent taste.' That's the kind of content that goes viral."

**Journey Outcome:**
- Wins: Trending data for content inspiration is genuinely novel. Marketing Assets for quick image downloads. Market share for location-specific content ideas.
- Friction: AI-generated social copy is ChatGPT-level (no differentiation). Rubric scoring doesn't suit creative content. No image editing/template tools. No brand voice training.
- Drop-off risk: MEDIUM. She'll use Trending for content ideas and Assets for downloads, but won't use Prompt Engine over ChatGPT for caption writing.
- "Aha moment": BREAKTHROUGH — realising she can use Trending + Market Share data to create data-driven, location-specific social content that no competitor can replicate.
- Time to value: 7 minutes (discovering Trending data for content creation).

---

## Support Tier

### 19. Rebecca — Finance Analyst
**Device:** Desktop (Windows) | **Time:** 15 mins | **Tech Comfort:** 4/5

**Entry point:** Damien asked her to check if The Hub's sales data matches their FloQast numbers.

**Step 1:** Logs in. Goes directly to Operations > Sales.
> Internal thought: "Damien wants me to verify these numbers. Let's compare."

**Step 2:** Opens Sales dashboard. Pulls up the latest week for all stores. Sees total revenue and store breakdown.
> Internal thought: "Let me compare this against the P&L. The total is $47.2M here vs $47.8M in FloQast. Close but not exact — probably timing differences or category treatment."

**Step 3:** Tries to export the data. No CSV button on the Sales page. Looks for a data export option.
> Internal thought: "I need to get this into Excel to reconcile. How do I export?"

**Step 4:** Discovers the dataframe tables have a small download icon when she hovers. Downloads a store-by-store breakdown.
> Internal thought: "Found it — the tiny icon in the top right of the table. Not obvious but it works."

**Step 5:** Opens Profitability dashboard. Compares gross margin by department against their internal P&L.
> Internal thought: "Margins are in the right range. Produce at 38% here vs 37.5% in our numbers. Close enough for directional use, not for audit."

**Step 6:** Checks Revenue Bridge — week-over-week and YoY revenue walk.
> Internal thought: "The revenue bridge is well-designed. Shows volume vs price vs mix decomposition. If this data matches our books close enough, it could save me the 2-hour weekly bridge I build in Excel."

**Journey Outcome:**
- Wins: Sales data is directionally accurate. Revenue bridge decomposition is sophisticated. Data export exists (hidden but functional).
- Friction: Export is hidden (tiny icon, not a button). Numbers don't exactly match FloQast — needs reconciliation notes explaining the differences.
- Drop-off risk: LOW. The revenue bridge alone could save her 2 hours weekly.
- "Aha moment": Revenue Bridge — volume/price/mix decomposition matching what she builds manually.
- Time to value: 4 minutes (comparing sales totals with FloQast).

---

## New Starter

### 20. Kai — Graduate Program Participant (Week 1)
**Device:** Laptop (MacBook) | **Time:** 30 mins | **Tech Comfort:** 5/5

**Entry point:** HR onboarding pack email: "Explore The Hub to learn about our five pillars and AI tools."

**Step 1:** Logs in with the password from the onboarding pack. Home page loads. Reads everything carefully — he's trying to learn.
> Internal thought: "Five pillars: Greater Goodness, Customer, People, Operations, Digital & AI. This is the company strategy. Let me understand each one."

**Step 2:** Clicks each pillar intro page systematically. Greater Goodness: sustainability, B-Corp, renewable energy. People: Academy, learning, AI skills. Operations: 43 stores, 383M transactions. Digital & AI: the platform itself.
> Internal thought: "This is actually a really good way to understand the company. Each intro page tells me the strategic question and the key metrics. Way better than the PowerPoint from orientation."

**Step 3:** Opens the Academy. Finds the gamification system — XP, levels, daily challenges, badges. Completes a daily challenge.
> Internal thought: "I earned 50 XP! I'm a 'Seed' now. This is like Duolingo for work. I want to hit 'Sprout' by end of week."

**Step 4:** Tries the Prompt Engine. Generates a "First 90 Days Plan" using the template. The AI creates a structured plan with Harris Farm-specific onboarding steps.
> Internal thought: "This is impressive. The AI knows about the company structure and created a real plan, not generic advice. I'm going to show this to my grad program manager."

**Step 5:** Opens Hub Assistant. Asks: "What are the Golden Rules?" Gets a comprehensive answer from the knowledge base.
> Internal thought: "The chatbot knows everything about company policies. This is way faster than searching through the induction folder."

**Step 6:** Explores Mission Control. Finds the Documentation tab, Data Catalog. Reads about the system architecture.
> Internal thought: "If I'm rotating through Digital & AI, understanding this architecture is going to be really valuable. I can see how everything connects."

**Step 7:** Checks the Way of Working. Sees 100 initiatives tracked from Monday.com. Browses the ones related to his rotation area.
> Internal thought: "I can see what every team is working on. This gives me context before I meet anyone. I'll know what projects exist before my first 1:1."

**Step 8:** Goes back to Academy. Checks the leaderboard — he's the only person on it. Earns a badge: "First Steps".
> Internal thought: "I'm #1 on the leaderboard! (Because I'm the only one here.) But seriously, this gamification is going to work with the other grads — we're competitive."

**Journey Outcome:**
- Wins: Pillar intro pages are an excellent strategic onboarding tool. Academy gamification hooks immediately. Hub Assistant for policy Q&A. Way of Working for organisational context. Prompt Engine for first-90-days planning.
- Friction: Empty leaderboard (he's alone). Some pages are clearly built for power users (Analytics Engine, PLU Intelligence) that a grad doesn't need yet.
- Drop-off risk: VERY LOW. This is the most engaged persona. He'll be an advocate.
- "Aha moment": Multiple — the pillar intro pages as strategic onboarding, the AI generating a personalised 90-day plan, seeing all 100 initiatives across the company.
- Time to value: 2 minutes (understanding the company strategy through pillar intros).

---

## Journey Summary

| # | Persona | Value Reached? | Time to Value | Drop-off Risk | Would Return? |
|---|---------|---------------|---------------|---------------|---------------|
| 1 | Angus (Co-CEO) | Yes | 2 min | Low | Yes |
| 2 | Damien (CFO) | Partial | 3 min | High | Unlikely |
| 3 | Sean (Head of Ops) | Yes | 4 min | Low | Yes |
| 4 | Laura (Head of People) | Yes | 5 min | Medium | Yes |
| 5 | Phil (CTO) | Yes | Immediate | Zero | Yes (owns it) |
| 6 | Karen (Store Mgr, Large) | Yes | 3 min | Low | Yes |
| 7 | Trevor (Store Mgr, Small) | **No** | Never | **Critical** | **No** |
| 8 | Marco (Produce DM) | **No** | Never | **Critical** | **No** |
| 9 | Zara (Weekend Buyer) | Yes | 3 min | Low | Yes |
| 10 | Bella (New Casual) | Partial | 4 min | Medium | Maybe |
| 11 | Darren (Warehouse) | **No** | Never | **Critical** | **No** |
| 12 | Priya (Transport) | Partial | 2 min | Low-Med | Monthly |
| 13 | James (Procurement) | Yes | 3 min | Very Low | Yes |
| 14 | Sophie (CMO) | Partial | 2 min | High | Unlikely |
| 15 | Megan (Brand Mgr) | Partial | 2 min | Medium | For assets only |
| 16 | Josh (Digital CRM) | Partial | 3 min | Medium | For first drafts |
| 17 | Liam (Mkt Analyst) | Yes | 2 min | Low | Yes |
| 18 | Tilly (Content Creator) | Yes | 7 min | Medium | For data-driven ideas |
| 19 | Rebecca (Finance) | Yes | 4 min | Low | Yes |
| 20 | Kai (Grad) | Yes | 2 min | Very Low | Yes (advocate) |

**Failed journeys (3):** Trevor (Store Mgr), Marco (Produce DM), Darren (Warehouse)
**Breakthrough moments (2+):** Kai (strategic onboarding via pillar intros), Tilly (data-driven content creation via Trending + Market Share), James (PLU Intelligence replacing manual Excel)
